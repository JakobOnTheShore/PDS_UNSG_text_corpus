{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5672ab24",
   "metadata": {},
   "source": [
    " code by Huan Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "694a3edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import subprocess\n",
    "import pytesseract\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "#  Tesseract executable path\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3295b8",
   "metadata": {},
   "source": [
    "#  Read single image - based pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b93ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# project root\n",
    "BASE_DIR = Path.cwd()\n",
    "SPEECHES_DIR = BASE_DIR / \"data\" / \"speeches\"\n",
    "# input\n",
    "PDF_DIR = SPEECHES_DIR / \"pdf\"\n",
    "# output\n",
    "PDF_SINGLE_COLUMN_DIR = SPEECHES_DIR / \"pdf_single_column\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdb9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFRAMES_DIR = BASE_DIR / \"data\" / \"dataframes\"\n",
    "META_PATH = DATAFRAMES_DIR / \"metadata_s03.csv\"\n",
    "\n",
    "df = pd.read_csv(META_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b40063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter text_based == False and two_column_layout == True\n",
    "trial_df = df[(df[\"text_based\"] == False) & (df[\"two_column_layout\"] == True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd581fa",
   "metadata": {},
   "source": [
    "Convert two columns into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62094b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_single_column(\n",
    "    pdf_name: str,\n",
    "    input_dir=PDF_DIR,\n",
    "    output_dir=PDF_SINGLE_COLUMN_DIR,\n",
    "    k2_path=None,\n",
    "    timeout=600,\n",
    "    debug=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert a two-column PDF to single-column using k2pdfopt.\n",
    "    If the output file already exists, skip conversion.\n",
    "    \"\"\"\n",
    "\n",
    "    input_pdf = input_dir / pdf_name\n",
    "    if not input_pdf.exists():\n",
    "        raise FileNotFoundError(f\"Input PDF not found: {input_pdf}\")\n",
    "\n",
    "    output_pdf = output_dir / pdf_name\n",
    "\n",
    "    if output_pdf.exists():\n",
    "        print(f\"⏭️  Skipped: {pdf_name} already exists.\")\n",
    "        return output_pdf\n",
    "\n",
    "    exe = k2_path or shutil.which(\"k2pdfopt\") or shutil.which(\"k2pdfopt.exe\")\n",
    "    if not exe:\n",
    "        raise FileNotFoundError(\"k2pdfopt not found, please ensure it is installed.\")\n",
    "\n",
    "    cmd = [\n",
    "        exe, str(input_pdf),\n",
    "        \"-o\", str(output_pdf),\n",
    "        \"-mode\",  \"copy\",\n",
    "        \"-col\", \"2\",\n",
    "        \"-ui-\",\n",
    "        \"-p\", \"3-9999\",\n",
    "        \"-x\",\n",
    "        \"-wrap-\",\n",
    "        \"-autorotate-\",\n",
    "        \"-rt\", \"0\",\n",
    "        \"-verbose\"\n",
    "    ]\n",
    "\n",
    "    res = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)\n",
    "\n",
    "    if debug:\n",
    "        print(\"\\n========== k2pdfopt DEBUG ==========\")\n",
    "        print(f\"PDF: {pdf_name}\")\n",
    "        print(\"CMD:\")\n",
    "        print(\" \".join(cmd))\n",
    "        print(\"\\n----- STDOUT -----\")\n",
    "        print(res.stdout)\n",
    "        print(\"\\n----- STDERR -----\")\n",
    "        print(res.stderr)\n",
    "        print(\"===================================\\n\")\n",
    "\n",
    "    if res.returncode != 0:\n",
    "        raise RuntimeError(f\"k2pdfopt error: {res.stderr or res.stdout}\")\n",
    "\n",
    "    if not output_pdf.exists() or output_pdf.stat().st_size < 5000:\n",
    "        raise RuntimeError(f\"Output file error, please check: {output_pdf}\")\n",
    "\n",
    "    print(f\"✅ Conversion successful: {output_pdf.name} → {output_pdf.stat().st_size // 1024} KB\")\n",
    "    return output_pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628b34f",
   "metadata": {},
   "source": [
    "Run the code on the whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6077a289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Skipped: A_1950_PV.289_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1951_PV.348_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1957_PV.690_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1960_PV.871_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1960_PV.883_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1960_PV.904_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1960_PV.906_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1979_34_PV.17_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1983_38_PV.81_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1983_38_PV.90_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1984_39_PV.44_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1984_39_PV.83_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1984_39_PV.96_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1993_48_PV.71_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1993_48_PV.74_speeches.pdf already exists.\n",
      "⏭️  Skipped: A_1994_48_PV.95_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1964_PV.1097_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1964_PV.1102_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1964_PV.1103_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1964_PV.1121_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1964_PV.1123_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1964_PV.1126_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1964_PV.1135_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1964_PV.1143_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1964_PV.1144_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1964_PV.1151_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1964_PV.1159_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1964_PV.1162_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1207_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1209_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1208_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1212_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1215_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1214_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1217_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1216_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1222_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1223_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1227_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1228_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1238_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1239_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1242_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1252_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1965_PV.1270_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1966_PV.1275_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1966_PV.1280_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1966_PV.1308_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1966_PV.1309_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1966_PV.1312_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1966_PV.1320_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1966_PV.1325_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1966_PV.1326_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1347_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1350_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1349_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1351_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1353_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1352_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1356_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1355_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1354_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1357_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1361_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1365_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1366_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1371_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1967_PV.1386_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1968_PV.1419_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1968_PV.1448_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1968_PV.1449_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1968_PV.1454_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1968_PV.1459_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1968_PV.1461_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1969_PV.1469_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1969_PV.1512_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1970_PV.1538_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1970_PV.1537_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1970_PV.1551_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1970_PV.1556_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1970_PV.1558_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1972_PV.1625_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1972_PV.1627_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1972_PV.1637_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1972_PV.1646_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1972_PV.1656_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1972_PV.1657_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1972_PV.1678_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1695_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1701_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1703_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1710_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1717_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1721_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1725_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1744_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1745_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1748_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1749_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1750_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1751_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1754_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1756_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1973_PV.1759_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1773_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1774_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1779_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1781_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1782_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1783_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1784_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1785_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1787_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1788_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1789_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1793_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1794_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1799_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1809_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1974_PV.1810_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1975_PV.1814_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1975_PV.1830_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1975_PV.1833_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1975_PV.1851_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1975_PV.1852_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1975_PV.1854_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1975_PV.1856_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1975_PV.1863_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1976_PV.1870_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1976_PV.1879_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1976_PV.1892_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1976_PV.1923_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1976_PV.1927_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1976_PV.1939_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1976_PV.1955_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1976_PV.1964_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1976_PV.1979_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1976_PV.1980_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1977_PV.1985_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1977_PV.1993_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1977_PV.2007_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1977_PV.2006_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1977_PV.2010_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1977_PV.2012_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1977_PV.2028_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1977_PV.2034_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1977_PV.2035_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1977_PV.2046_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1977_PV.2051_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1977_PV.2055_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1978_PV.2075_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1978_PV.2074_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1978_PV.2076_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1978_PV.2079_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1978_PV.2082_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1978_PV.2085_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1978_PV.2087_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1978_PV.2106_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1979_PV.2113_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1979_PV.2146_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1979_PV.2147_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1979_PV.2150_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1979_PV.2172_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1979_PV.2178_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1979_PV.2179_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1979_PV.2180_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1979_PV.2181_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1979_PV.2182_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1980_PV.2191_ANDADD.1_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1980_PV.2212_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1980_PV.2213_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1980_PV.2230_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1980_PV.2232_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1980_PV.2247_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1980_PV.2248_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1980_PV.2257_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1980_PV.2258_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1980_PV.2261_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1980_PV.2259_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1981_PV.2263_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1981_PV.2278_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1981_PV.2279_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1981_PV.2289_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1981_PV.2292_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1981_PV.2293_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1981_PV.2294_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1981_PV.2313_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1981_PV.2320_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1981_PV.2321_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1982_PV.2329_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1982_PV.2360_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1982_PV.2368_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1982_PV.2371_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1982_PV.2374_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1982_PV.2375_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1982_PV.2376_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1982_PV.2396_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1982_PV.2399_ANDCORR.1_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1982_PV.2406_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1983_PV.2411_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1983_PV.2497_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1984_PV.2519_speeches.pdf already exists.\n",
      "⏭️  Skipped: S_1985_PV.2608_speeches.pdf already exists.\n",
      "====== TRIAL SUMMARY ======\n",
      "OK: 203 ['A_1950_PV.289_speeches.pdf', 'A_1951_PV.348_speeches.pdf', 'A_1957_PV.690_speeches.pdf', 'A_1960_PV.871_speeches.pdf', 'A_1960_PV.883_speeches.pdf', 'A_1960_PV.904_speeches.pdf', 'A_1960_PV.906_speeches.pdf', 'A_1979_34_PV.17_speeches.pdf', 'A_1983_38_PV.81_speeches.pdf', 'A_1983_38_PV.90_speeches.pdf', 'A_1984_39_PV.44_speeches.pdf', 'A_1984_39_PV.83_speeches.pdf', 'A_1984_39_PV.96_speeches.pdf', 'A_1993_48_PV.71_speeches.pdf', 'A_1993_48_PV.74_speeches.pdf', 'A_1994_48_PV.95_speeches.pdf', 'S_1964_PV.1097_speeches.pdf', 'S_1964_PV.1102_speeches.pdf', 'S_1964_PV.1103_speeches.pdf', 'S_1964_PV.1121_speeches.pdf', 'S_1964_PV.1123_speeches.pdf', 'S_1964_PV.1126_speeches.pdf', 'S_1964_PV.1135_speeches.pdf', 'S_1964_PV.1143_speeches.pdf', 'S_1964_PV.1144_speeches.pdf', 'S_1964_PV.1151_speeches.pdf', 'S_1964_PV.1159_speeches.pdf', 'S_1964_PV.1162_speeches.pdf', 'S_1965_PV.1207_speeches.pdf', 'S_1965_PV.1209_speeches.pdf', 'S_1965_PV.1208_speeches.pdf', 'S_1965_PV.1212_speeches.pdf', 'S_1965_PV.1215_speeches.pdf', 'S_1965_PV.1214_speeches.pdf', 'S_1965_PV.1217_speeches.pdf', 'S_1965_PV.1216_speeches.pdf', 'S_1965_PV.1222_speeches.pdf', 'S_1965_PV.1223_speeches.pdf', 'S_1965_PV.1227_speeches.pdf', 'S_1965_PV.1228_speeches.pdf', 'S_1965_PV.1238_speeches.pdf', 'S_1965_PV.1239_speeches.pdf', 'S_1965_PV.1242_speeches.pdf', 'S_1965_PV.1252_speeches.pdf', 'S_1965_PV.1270_speeches.pdf', 'S_1966_PV.1275_speeches.pdf', 'S_1966_PV.1280_speeches.pdf', 'S_1966_PV.1308_speeches.pdf', 'S_1966_PV.1309_speeches.pdf', 'S_1966_PV.1312_speeches.pdf', 'S_1966_PV.1320_speeches.pdf', 'S_1966_PV.1325_speeches.pdf', 'S_1966_PV.1326_speeches.pdf', 'S_1967_PV.1347_speeches.pdf', 'S_1967_PV.1350_speeches.pdf', 'S_1967_PV.1349_speeches.pdf', 'S_1967_PV.1351_speeches.pdf', 'S_1967_PV.1353_speeches.pdf', 'S_1967_PV.1352_speeches.pdf', 'S_1967_PV.1356_speeches.pdf', 'S_1967_PV.1355_speeches.pdf', 'S_1967_PV.1354_speeches.pdf', 'S_1967_PV.1357_speeches.pdf', 'S_1967_PV.1361_speeches.pdf', 'S_1967_PV.1365_speeches.pdf', 'S_1967_PV.1366_speeches.pdf', 'S_1967_PV.1371_speeches.pdf', 'S_1967_PV.1386_speeches.pdf', 'S_1968_PV.1419_speeches.pdf', 'S_1968_PV.1448_speeches.pdf', 'S_1968_PV.1449_speeches.pdf', 'S_1968_PV.1454_speeches.pdf', 'S_1968_PV.1459_speeches.pdf', 'S_1968_PV.1461_speeches.pdf', 'S_1969_PV.1469_speeches.pdf', 'S_1969_PV.1512_speeches.pdf', 'S_1970_PV.1538_speeches.pdf', 'S_1970_PV.1537_speeches.pdf', 'S_1970_PV.1551_speeches.pdf', 'S_1970_PV.1556_speeches.pdf', 'S_1970_PV.1558_speeches.pdf', 'S_1972_PV.1625_speeches.pdf', 'S_1972_PV.1627_speeches.pdf', 'S_1972_PV.1637_speeches.pdf', 'S_1972_PV.1646_speeches.pdf', 'S_1972_PV.1656_speeches.pdf', 'S_1972_PV.1657_speeches.pdf', 'S_1972_PV.1678_speeches.pdf', 'S_1973_PV.1695_speeches.pdf', 'S_1973_PV.1701_speeches.pdf', 'S_1973_PV.1703_speeches.pdf', 'S_1973_PV.1710_speeches.pdf', 'S_1973_PV.1717_speeches.pdf', 'S_1973_PV.1721_speeches.pdf', 'S_1973_PV.1725_speeches.pdf', 'S_1973_PV.1744_speeches.pdf', 'S_1973_PV.1745_speeches.pdf', 'S_1973_PV.1748_speeches.pdf', 'S_1973_PV.1749_speeches.pdf', 'S_1973_PV.1750_speeches.pdf', 'S_1973_PV.1751_speeches.pdf', 'S_1973_PV.1754_speeches.pdf', 'S_1973_PV.1756_speeches.pdf', 'S_1973_PV.1759_speeches.pdf', 'S_1974_PV.1773_speeches.pdf', 'S_1974_PV.1774_speeches.pdf', 'S_1974_PV.1779_speeches.pdf', 'S_1974_PV.1781_speeches.pdf', 'S_1974_PV.1782_speeches.pdf', 'S_1974_PV.1783_speeches.pdf', 'S_1974_PV.1784_speeches.pdf', 'S_1974_PV.1785_speeches.pdf', 'S_1974_PV.1787_speeches.pdf', 'S_1974_PV.1788_speeches.pdf', 'S_1974_PV.1789_speeches.pdf', 'S_1974_PV.1793_speeches.pdf', 'S_1974_PV.1794_speeches.pdf', 'S_1974_PV.1799_speeches.pdf', 'S_1974_PV.1809_speeches.pdf', 'S_1974_PV.1810_speeches.pdf', 'S_1975_PV.1814_speeches.pdf', 'S_1975_PV.1830_speeches.pdf', 'S_1975_PV.1833_speeches.pdf', 'S_1975_PV.1851_speeches.pdf', 'S_1975_PV.1852_speeches.pdf', 'S_1975_PV.1854_speeches.pdf', 'S_1975_PV.1856_speeches.pdf', 'S_1975_PV.1863_speeches.pdf', 'S_1976_PV.1870_speeches.pdf', 'S_1976_PV.1879_speeches.pdf', 'S_1976_PV.1892_speeches.pdf', 'S_1976_PV.1923_speeches.pdf', 'S_1976_PV.1927_speeches.pdf', 'S_1976_PV.1939_speeches.pdf', 'S_1976_PV.1955_speeches.pdf', 'S_1976_PV.1964_speeches.pdf', 'S_1976_PV.1979_speeches.pdf', 'S_1976_PV.1980_speeches.pdf', 'S_1977_PV.1985_speeches.pdf', 'S_1977_PV.1993_speeches.pdf', 'S_1977_PV.2007_speeches.pdf', 'S_1977_PV.2006_speeches.pdf', 'S_1977_PV.2010_speeches.pdf', 'S_1977_PV.2012_speeches.pdf', 'S_1977_PV.2028_speeches.pdf', 'S_1977_PV.2034_speeches.pdf', 'S_1977_PV.2035_speeches.pdf', 'S_1977_PV.2046_speeches.pdf', 'S_1977_PV.2051_speeches.pdf', 'S_1977_PV.2055_speeches.pdf', 'S_1978_PV.2075_speeches.pdf', 'S_1978_PV.2074_speeches.pdf', 'S_1978_PV.2076_speeches.pdf', 'S_1978_PV.2079_speeches.pdf', 'S_1978_PV.2082_speeches.pdf', 'S_1978_PV.2085_speeches.pdf', 'S_1978_PV.2087_speeches.pdf', 'S_1978_PV.2106_speeches.pdf', 'S_1979_PV.2113_speeches.pdf', 'S_1979_PV.2146_speeches.pdf', 'S_1979_PV.2147_speeches.pdf', 'S_1979_PV.2150_speeches.pdf', 'S_1979_PV.2172_speeches.pdf', 'S_1979_PV.2178_speeches.pdf', 'S_1979_PV.2179_speeches.pdf', 'S_1979_PV.2180_speeches.pdf', 'S_1979_PV.2181_speeches.pdf', 'S_1979_PV.2182_speeches.pdf', 'S_1980_PV.2191_ANDADD.1_speeches.pdf', 'S_1980_PV.2212_speeches.pdf', 'S_1980_PV.2213_speeches.pdf', 'S_1980_PV.2230_speeches.pdf', 'S_1980_PV.2232_speeches.pdf', 'S_1980_PV.2247_speeches.pdf', 'S_1980_PV.2248_speeches.pdf', 'S_1980_PV.2257_speeches.pdf', 'S_1980_PV.2258_speeches.pdf', 'S_1980_PV.2261_speeches.pdf', 'S_1980_PV.2259_speeches.pdf', 'S_1981_PV.2263_speeches.pdf', 'S_1981_PV.2278_speeches.pdf', 'S_1981_PV.2279_speeches.pdf', 'S_1981_PV.2289_speeches.pdf', 'S_1981_PV.2292_speeches.pdf', 'S_1981_PV.2293_speeches.pdf', 'S_1981_PV.2294_speeches.pdf', 'S_1981_PV.2313_speeches.pdf', 'S_1981_PV.2320_speeches.pdf', 'S_1981_PV.2321_speeches.pdf', 'S_1982_PV.2329_speeches.pdf', 'S_1982_PV.2360_speeches.pdf', 'S_1982_PV.2368_speeches.pdf', 'S_1982_PV.2371_speeches.pdf', 'S_1982_PV.2374_speeches.pdf', 'S_1982_PV.2375_speeches.pdf', 'S_1982_PV.2376_speeches.pdf', 'S_1982_PV.2396_speeches.pdf', 'S_1982_PV.2399_ANDCORR.1_speeches.pdf', 'S_1982_PV.2406_speeches.pdf', 'S_1983_PV.2411_speeches.pdf', 'S_1983_PV.2497_speeches.pdf', 'S_1984_PV.2519_speeches.pdf', 'S_1985_PV.2608_speeches.pdf']\n",
      "FAIL: 0\n",
      "\n",
      "⏱️ Total runtime: 0.0 minutes\n"
     ]
    }
   ],
   "source": [
    "K2_PATH=r\"D:\\LeStoreDownload\\k2pdfopt.exe\"\n",
    "ok, fail = [], []\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "for _, row in trial_df.iterrows():\n",
    "    pdf_name = row[\"file_name_pdf\"]\n",
    "    try:\n",
    "        out_pdf = convert_to_single_column(\n",
    "            pdf_name,\n",
    "            input_dir=PDF_DIR,\n",
    "            output_dir=PDF_SINGLE_COLUMN_DIR,\n",
    "            k2_path=K2_PATH,\n",
    "            debug=False\n",
    "        )\n",
    "        ok.append(pdf_name)\n",
    "    except Exception as e:\n",
    "        fail.append((pdf_name, str(e)))\n",
    "        print(f\"❌ FAIL: {pdf_name}\\n   {e}\\n\")\n",
    "\n",
    "print(\"====== TRIAL SUMMARY ======\")\n",
    "print(\"OK:\", len(ok), ok)\n",
    "print(\"FAIL:\", len(fail))\n",
    "for x in fail:\n",
    "    print(\" -\", x[0], \"=>\", x[1][:160])\n",
    "\n",
    "total_sec = time.time() - t0\n",
    "print(f\"\\n⏱️ Total runtime: {total_sec/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d79db088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a0a675",
   "metadata": {},
   "source": [
    "# evaluate the output via accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b51a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# import pandas as pd\n",
    "# import spacy\n",
    "# from wordfreq import zipf_frequency\n",
    "\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_lg\", disable=[\"parser\", \"tagger\"])  # only used for lemmatization and vocab, no need for parser and tagger\n",
    "\n",
    "# def evaluate_precise(text, nlp):\n",
    "#     \"\"\"\n",
    "#     Lightweight OCR lexical quality evaluation.\n",
    "\n",
    "#     Logic:\n",
    "#     - Tokenize text using spaCy\n",
    "#     - Ignore non-alphabetic tokens\n",
    "#     - Treat proper nouns as valid\n",
    "#     - For other words, check lemma frequency using wordfreq (Zipf scale)\n",
    "#     - Words with extremely low frequency are considered likely OCR errors\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     text : str\n",
    "#         OCR-extracted text\n",
    "#     nlp : spacy.Language\n",
    "#         Loaded spaCy English model\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     accuracy : float\n",
    "#         Ratio of lexically valid words\n",
    "#     df_invalid : pd.DataFrame\n",
    "#         Frequency table of likely incorrect words\n",
    "#     \"\"\"\n",
    "\n",
    "#     doc = nlp(text)\n",
    "\n",
    "#     total = 0\n",
    "#     invalid_words = []\n",
    "\n",
    "#     # Cache to avoid repeated frequency lookup\n",
    "#     valid_cache = {}  # word -> True / False\n",
    "\n",
    "#     for token in doc:\n",
    "\n",
    "#         # Skip punctuation, numbers, symbols\n",
    "#         if not token.is_alpha:\n",
    "#             continue\n",
    "\n",
    "#         total += 1\n",
    "\n",
    "#         txt = token.text\n",
    "#         lemma = token.lemma_\n",
    "\n",
    "#         # ---------- Proper noun rule ----------\n",
    "#         # Capitalized words inside sentences are assumed to be valid\n",
    "#         is_proper = txt[0].isupper() and not token.is_sent_start\n",
    "#         if is_proper:\n",
    "#             continue\n",
    "\n",
    "#         # ---------- Frequency check ----------\n",
    "#         w = lemma.lower()\n",
    "\n",
    "#         if w in valid_cache:\n",
    "#             ok = valid_cache[w]\n",
    "#         else:\n",
    "#             ok = zipf_frequency(w, \"en\") > 1.5  # empirical threshold\n",
    "#             valid_cache[w] = ok\n",
    "\n",
    "#         if not ok:\n",
    "#             invalid_words.append(w)\n",
    "\n",
    "#     # ---------- Aggregate invalid words ----------\n",
    "#     invalid_freq = Counter(invalid_words)\n",
    "\n",
    "#     df_invalid = (\n",
    "#         pd.DataFrame(invalid_freq.items(),\n",
    "#                      columns=[\"invalid_word\", \"frequency\"])\n",
    "#         .sort_values(\"frequency\", ascending=False)\n",
    "#     )\n",
    "\n",
    "#     accuracy = (total - len(invalid_words)) / total if total > 0 else 0.0\n",
    "\n",
    "#     return accuracy, df_invalid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d0511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\54241\\anaconda3\\envs\\ds_project\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Lexical Accuracy: 99.04%\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "invalid_word",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frequency",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "cce7c978-8290-4a36-8843-dec2792db46b",
       "rows": [
        [
         "29",
         "nesia",
         "14"
        ],
        [
         "30",
         "ations",
         "4"
        ],
        [
         "71",
         "pendence",
         "3"
        ],
        [
         "70",
         "donesia",
         "3"
        ],
        [
         "24",
         "ebate",
         "2"
        ],
        [
         "33",
         "sembly",
         "2"
        ],
        [
         "0",
         "ccccccccvccccccccccccccsecucesuceeeeuees",
         "1"
        ],
        [
         "74",
         "saiute",
         "1"
        ],
        [
         "72",
         "cories",
         "1"
        ],
        [
         "69",
         "addrressing",
         "1"
        ],
        [
         "68",
         "ccuntries",
         "1"
        ],
        [
         "67",
         "reperesentative",
         "1"
        ],
        [
         "66",
         "welcon",
         "1"
        ],
        [
         "65",
         "fident",
         "1"
        ],
        [
         "64",
         "establishraent",
         "1"
        ],
        [
         "63",
         "gation",
         "1"
        ],
        [
         "62",
         "ccuntry",
         "1"
        ],
        [
         "61",
         "delegution",
         "1"
        ],
        [
         "60",
         "fordign",
         "1"
        ],
        [
         "59",
         "dslegation",
         "1"
        ],
        [
         "58",
         "larly",
         "1"
        ],
        [
         "57",
         "becatise",
         "1"
        ],
        [
         "56",
         "indejsendence",
         "1"
        ],
        [
         "55",
         "ponement",
         "1"
        ],
        [
         "54",
         "junture",
         "1"
        ],
        [
         "73",
         "shovid",
         "1"
        ],
        [
         "75",
         "onty",
         "1"
        ],
        [
         "52",
         "acean",
         "1"
        ],
        [
         "88",
         "artner",
         "1"
        ],
        [
         "98",
         "opment",
         "1"
        ],
        [
         "97",
         "nomic",
         "1"
        ],
        [
         "96",
         "nesian",
         "1"
        ],
        [
         "95",
         "mittee",
         "1"
        ],
        [
         "94",
         "rminated",
         "1"
        ],
        [
         "93",
         "promptitude",
         "1"
        ],
        [
         "92",
         "viduals",
         "1"
        ],
        [
         "91",
         "peopie",
         "1"
        ],
        [
         "90",
         "indeperdent",
         "1"
        ],
        [
         "89",
         "akistan",
         "1"
        ],
        [
         "87",
         "shqwed",
         "1"
        ],
        [
         "76",
         "tunity",
         "1"
        ],
        [
         "86",
         "mitted",
         "1"
        ],
        [
         "85",
         "themseives",
         "1"
        ],
        [
         "84",
         "imdependence",
         "1"
        ],
        [
         "83",
         "gratulated",
         "1"
        ],
        [
         "82",
         "ganization",
         "1"
        ],
        [
         "81",
         "tites",
         "1"
        ],
        [
         "80",
         "perialist",
         "1"
        ],
        [
         "79",
         "ublic",
         "1"
        ],
        [
         "78",
         "perity",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 100
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invalid_word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>nesia</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ations</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pendence</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>donesia</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ebate</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>wislies</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bership</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>consicer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>archipelagoes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     invalid_word  frequency\n",
       "29          nesia         14\n",
       "30         ations          4\n",
       "71       pendence          3\n",
       "70        donesia          3\n",
       "24          ebate          2\n",
       "..            ...        ...\n",
       "32        wislies          1\n",
       "31         tative          1\n",
       "28        bership          1\n",
       "27       consicer          1\n",
       "99  archipelagoes          1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy, df_invalid = evaluate_precise(text, nlp)\n",
    "# print(f\"OCR Lexical Accuracy: {accuracy*100:.2f}%\")\n",
    "# df_invalid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
